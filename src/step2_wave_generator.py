import pandas as pd
import numpy as np
import os
import sys
from datetime import datetime, timedelta

# ==========================================
# è¨­å®šæª”æ¡ˆè·¯å¾‘
# ==========================================
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_MASTER_DIR = os.path.join(BASE_DIR, 'data', 'master')
DATA_TRANSACTION_DIR = os.path.join(BASE_DIR, 'data', 'transaction')

# è¼¸å…¥æª”æ¡ˆ
ROUTE_SCHEDULE_FILE = 'route_schedule_master.csv'
HISTORICAL_ORDERS_FILE = 'historical_orders_ex.csv'
OUTPUT_WAVE_FILE = 'wave_orders.csv'

def read_csv_robust(file_path, dtype=None):
    """
    å¼·å¥çš„ CSV è®€å–å‡½å¼ï¼Œè‡ªå‹•å˜—è©¦ utf-8 èˆ‡ cp950 (Big5) ç·¨ç¢¼
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æª”æ¡ˆ: {file_path}")

    encodings = ['utf-8', 'cp950', 'big5', 'gbk']
    
    for enc in encodings:
        try:
            # åŠ å…¥ low_memory=False èˆ‡ dtype æŒ‡å®šï¼Œæå‡è®€å–ç©©å®šåº¦
            df = pd.read_csv(file_path, encoding=enc, dtype=dtype, low_memory=False)
            return df
        except UnicodeDecodeError:
            continue
        except Exception as e:
            raise e
            
    raise ValueError(f"ç„¡æ³•è®€å–æª”æ¡ˆ {os.path.basename(file_path)}ï¼Œè«‹ç¢ºèªç·¨ç¢¼")

def parse_time_str(time_str):
    """
    å°‡ '855' (int/str) æˆ– '08:55:00' è½‰ç‚º time object
    """
    s = str(time_str).strip()
    if not s or s.lower() == 'nan': return None
    
    if ':' in s:
        # æ ¼å¼: 08:55:00 æˆ– 08:55
        try:
            return datetime.strptime(s, "%H:%M:%S").time()
        except ValueError:
            try:
                return datetime.strptime(s, "%H:%M").time()
            except ValueError:
                return None
    else:
        # æ ¼å¼: 855 -> 08:55
        if s.isdigit():
            s = s.zfill(4)
            try:
                return datetime.strptime(s, "%H%M").time()
            except ValueError:
                return None
        return None

def load_route_schedule():
    path = os.path.join(DATA_MASTER_DIR, ROUTE_SCHEDULE_FILE)
    print(f"ğŸ“– æ­£åœ¨è®€å–ç­æ¬¡è¡¨: {ROUTE_SCHEDULE_FILE} ...")
    
    # å¼·åˆ¶å°‡ ROUTECD å’Œ PARTCUSTID è®€ç‚ºå­—ä¸²ï¼Œé¿å…å‹åˆ¥æ··äº‚
    df = read_csv_robust(path, dtype={'ROUTECD': str, 'PARTCUSTID': str})
    
    schedule_map = {}
    count = 0
    
    # æ¸…æ´—è³‡æ–™
    df['ROUTECD'] = df['ROUTECD'].str.strip()
    df['PARTCUSTID'] = df['PARTCUSTID'].str.strip()
    
    # ç§»é™¤ç©ºå€¼
    df.dropna(subset=['ROUTECD', 'PARTCUSTID', 'ORDERENDTIME'], inplace=True)
    
    for _, row in df.iterrows():
        key = (row['ROUTECD'], row['PARTCUSTID'])
        t = parse_time_str(row['ORDERENDTIME'])
        
        if t:
            if key not in schedule_map: schedule_map[key] = []
            schedule_map[key].append(t)
            count += 1
            
    for k in schedule_map:
        schedule_map[k].sort()
        
    print(f"   -> å·²å»ºç«‹ {len(schedule_map)} çµ„å®¢æˆ¶ç­æ¬¡è¦å‰‡ (å…± {count} å€‹ç­æ¬¡æ™‚é–“é»)")
    return schedule_map

def assign_wave(order_datetime, schedule_times):
    order_time = order_datetime.time()
    
    for cutoff_time in schedule_times:
        if order_time <= cutoff_time:
            wave_dt = datetime.combine(order_datetime.date(), cutoff_time)
            return wave_dt, False
            
    # è·¨æ—¥
    next_day = order_datetime.date() + timedelta(days=1)
    first_cutoff = schedule_times[0]
    wave_dt = datetime.combine(next_day, first_cutoff)
    return wave_dt, True

def main():
    print("ğŸš€ [Step 2] å•Ÿå‹•è¨‚å–®æ³¢æ¬¡ç”¢ç”Ÿå™¨ (è³‡æ–™æ¸…æ´—ç‰ˆ)...")
    
    # 1. è¼‰å…¥ç­æ¬¡è¡¨
    try:
        schedule_map = load_route_schedule()
    except Exception as e:
        print(f"âŒ ç­æ¬¡è¡¨è®€å–éŒ¯èª¤: {e}")
        sys.exit(1)
        
    # 2. è¼‰å…¥æ­·å²è¨‚å–®
    orders_path = os.path.join(DATA_TRANSACTION_DIR, HISTORICAL_ORDERS_FILE)
    print(f"ğŸ“– æ­£åœ¨è®€å–æ­·å²è¨‚å–®: {HISTORICAL_ORDERS_FILE} ...")
    
    try:
        # å¼·åˆ¶è®€å–ç‚ºå­—ä¸²ï¼Œå¾ŒçºŒå†è½‰å‹ï¼Œç¢ºä¿è³‡æ–™å®Œæ•´
        df_orders = read_csv_robust(orders_path, dtype=str)
    except Exception as e:
        print(f"âŒ è¨‚å–®æª”è®€å–éŒ¯èª¤: {e}")
        sys.exit(1)
    
    original_count = len(df_orders)
    
    # --- è³‡æ–™æ¸…æ´— ---
    print("ğŸ§¹ åŸ·è¡Œè³‡æ–™æ¸…æ´—...")
    # 1. ç§»é™¤ ROUTECD æˆ– PARTCUSTID ç‚ºç©ºçš„è¡Œ (è§£æ±º ,,,,,,, çš„å•é¡Œ)
    df_orders.dropna(subset=['ROUTECD', 'PARTCUSTID', 'DATE', 'TIME'], inplace=True)
    
    # 2. å»é™¤ç©ºç™½å­—å…ƒ
    df_orders['ROUTECD'] = df_orders['ROUTECD'].str.strip()
    df_orders['PARTCUSTID'] = df_orders['PARTCUSTID'].str.strip()
    
    # 3. è§£ææ™‚é–“
    try:
        # éŒ¯èª¤çš„æ™‚é–“æ ¼å¼è½‰ç‚º NaT
        df_orders['datetime'] = pd.to_datetime(df_orders['DATE'] + ' ' + df_orders['TIME'], errors='coerce')
        # ç§»é™¤æ™‚é–“è§£æå¤±æ•—çš„è¡Œ
        df_orders.dropna(subset=['datetime'], inplace=True)
    except Exception as e:
        print(f"âŒ æ™‚é–“æ ¼å¼è§£æåš´é‡éŒ¯èª¤: {e}")
        sys.exit(1)

    cleaned_count = len(df_orders)
    print(f"   -> åŸå§‹ç­†æ•¸: {original_count}, æ¸…æ´—å¾Œæœ‰æ•ˆç­†æ•¸: {cleaned_count} (å‰”é™¤ {original_count - cleaned_count} ç­†ç„¡æ•ˆè³‡æ–™)")

    if cleaned_count == 0:
        print("âŒ éŒ¯èª¤: æ¸…æ´—å¾Œæ²’æœ‰å‰©é¤˜ä»»ä½•è¨‚å–®ï¼è«‹æª¢æŸ¥ CSV å…§å®¹æ ¼å¼ã€‚")
        sys.exit(1)

    # 3. é€²è¡Œæ³¢æ¬¡åˆ†æ´¾
    print(f"âš™ï¸ é–‹å§‹åˆ†é…æ³¢æ¬¡...")
    
    wave_ids = []
    wave_timestamps = []
    is_next_day_list = []
    
    unmatched_keys = set()
    unmatched_count = 0
    
    for _, row in df_orders.iterrows():
        key = (row['ROUTECD'], row['PARTCUSTID'])
        
        if key in schedule_map:
            target_dt, is_next_day = assign_wave(row['datetime'], schedule_map[key])
            w_id = f"W_{target_dt.strftime('%Y%m%d_%H%M')}"
            
            wave_ids.append(w_id)
            wave_timestamps.append(target_dt)
            is_next_day_list.append(1 if is_next_day else 0)
        else:
            unmatched_count += 1
            if len(unmatched_keys) < 10: unmatched_keys.add(str(key))
            
            # Default Wave: ç•¶æ—¥ 23:59
            def_dt = datetime.combine(row['datetime'].date(), datetime.strptime("23:59", "%H:%M").time())
            wave_ids.append(f"W_{def_dt.strftime('%Y%m%d')}_DEFAULT")
            wave_timestamps.append(def_dt)
            is_next_day_list.append(0)
            
    df_orders['WAVE_ID'] = wave_ids
    df_orders['WAVE_DEADLINE'] = wave_timestamps
    df_orders['IS_ROLLOVER'] = is_next_day_list
    
    df_orders = df_orders.sort_values(by=['WAVE_DEADLINE', 'datetime'])
    
    output_path = os.path.join(DATA_TRANSACTION_DIR, OUTPUT_WAVE_FILE)
    df_orders.to_csv(output_path, index=False, encoding='utf-8-sig')
    
    print(f"âœ… æ³¢æ¬¡ç”Ÿæˆå®Œæˆï¼çµæœå·²å­˜æª”: {OUTPUT_WAVE_FILE}")
    print("\nğŸ“Š æ³¢æ¬¡çµ±è¨ˆæ‘˜è¦:")
    print(f"   -> æœ‰æ•ˆè¨‚å–®æ•¸: {cleaned_count}")
    print(f"   -> ç”Ÿæˆæ³¢æ¬¡æ•¸: {df_orders['WAVE_ID'].nunique()}")
    
    if unmatched_count > 0:
        print(f"   âš ï¸ è­¦å‘Š: æœ‰ {unmatched_count} ç­†è¨‚å–®æ‰¾ä¸åˆ°å°æ‡‰ç­æ¬¡ (æ­¸å…¥ DEFAULT)")
        print(f"   ğŸ” æ‰¾ä¸åˆ°ç­æ¬¡çš„ (Route, Cust) ç¯„ä¾‹: {list(unmatched_keys)}")
        print("      (è«‹ç¢ºèª route_schedule_master.csv æ˜¯å¦åŒ…å«é€™äº›çµ„åˆ)")
        
    print("\n   [ç¯„ä¾‹æ³¢æ¬¡åˆ†ä½ˆ (å‰ 5 ç­†)]:")
    print(df_orders[['WAVE_ID', 'ROUTECD', 'PARTCUSTID', 'datetime']].head(5).to_string())

if __name__ == "__main__":
    main()