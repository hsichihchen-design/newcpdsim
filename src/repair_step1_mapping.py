import pandas as pd
import numpy as np
import os
import random

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_MAP_DIR = os.path.join(BASE_DIR, 'data', 'master')
DATA_TRX_DIR = os.path.join(BASE_DIR, 'data', 'transaction')
OUTPUT_MAP_FILE = os.path.join(BASE_DIR, 'data', 'mapping', 'shelf_coordinate_map.csv')

def load_map_grid(filename):
    path = os.path.join(DATA_MAP_DIR, filename)
    if os.path.exists(path):
        try: return pd.read_excel(path, header=None).fillna(0).values
        except: pass
    # Try CSV
    csv_path = os.path.join(DATA_MAP_DIR, os.path.splitext(filename)[0] + ".csv")
    if os.path.exists(csv_path):
        try: return pd.read_csv(csv_path, header=None).fillna(0).values
        except: pass
    return None

def repair_mapping():
    print("ğŸ”§ å•Ÿå‹•åº§æ¨™æ˜ å°„ä¿®å¾©å·¥å…· (Mapping Repair)...")
    
    # 1. è®€å–çœŸå¯¦åœ°åœ–ä¸Šçš„æ–™æ¶é»
    shelf_spots = {'2F': [], '3F': []}
    
    for floor, filename in [('2F', '2F_map.xlsx'), ('3F', '3F_map.xlsx')]:
        grid = load_map_grid(filename)
        if grid is None:
            print(f"   âŒ ç„¡æ³•è®€å– {floor} åœ°åœ–")
            continue
            
        rows, cols = grid.shape
        count = 0
        # æƒææ‰€æœ‰æ ¼å­
        for r in range(rows):
            for c in range(cols):
                if grid[r][c] == 1: # 1 = æ–™æ¶
                    # æ³¨æ„ï¼šé€™è£¡å­˜å…¥ (x=Col, y=Row) ä»¥ç¬¦åˆè¦–è¦ºåŒ–ç¿’æ…£
                    shelf_spots[floor].append((c, r)) 
                    count += 1
        print(f"   âœ… {floor} åœ°åœ–ä¸­æ‰¾åˆ° {count} å€‹å¯¦é«”æ–™æ¶æ ¼")

    if not shelf_spots['2F'] and not shelf_spots['3F']:
        print("âŒ åš´é‡éŒ¯èª¤ï¼šåœ°åœ–ä¸Šå®Œå…¨æ²’æœ‰æ–™æ¶ (æ•¸å€¼ 1)ï¼ç„¡æ³•ä¿®å¾©ã€‚")
        return

    # 2. è®€å–æ‰€æœ‰è¨‚å–®ä¸­å‡ºç¾éçš„æ–™æ¶ ID
    # é€™è£¡æˆ‘å€‘éœ€è¦ä¸€å€‹æ¸…å–®ï¼Œå¦‚æœæ²’æœ‰æ¸…å–®ï¼Œæˆ‘å€‘å°±è®€ wave_orders.csv ä¾†æ”¶é›†
    print("ğŸ“¦ æ”¶é›†è¨‚å–®ä¸­çš„æ–™æ¶ ID...")
    order_path = os.path.join(DATA_TRX_DIR, 'wave_orders.csv')
    if not os.path.exists(order_path):
        print("âŒ æ‰¾ä¸åˆ°è¨‚å–®æª” wave_orders.csv")
        return

    try:
        df_orders = pd.read_csv(order_path, encoding='utf-8-sig')
    except:
        df_orders = pd.read_csv(order_path, encoding='cp950') # big5 fallback

    # å‡è¨­è¨‚å–®ä¸­æœ‰ shelf_id æ¬„ä½ï¼Œå¦‚æœæ²’æœ‰ï¼Œæˆ‘å€‘å°±ç”¨ Row Index ç•¶ä½œå‡ ID
    # ä½†é€šå¸¸æ‚¨çš„è³‡æ–™æºæ‡‰è©²éš±å«äº†æ–™æ¶è³‡è¨Šã€‚
    # ç‚ºäº†ä¿éšªï¼Œæˆ‘å€‘é‡æ–°ç”Ÿæˆä¸€ä»½å°æ‡‰è¡¨ã€‚
    
    # ç­–ç•¥ï¼šæˆ‘å€‘ç”¢ç”Ÿè¶³å¤ å¤šçš„è™›æ“¬ IDï¼Œæˆ–è€…é‡ç½®ç¾æœ‰çš„ map
    # è®“æˆ‘å€‘è®€å–èˆŠçš„ map ä¾†ç²å– ID æ¸…å–® (å¦‚æœæœ‰çš„è©±)
    old_map_path = OUTPUT_MAP_FILE
    shelf_ids = []
    
    if os.path.exists(old_map_path):
        print("   -> å¾èˆŠçš„ mapping æª”è®€å– ID...")
        try:
            df_old = pd.read_csv(old_map_path)
            shelf_ids = df_old['shelf_id'].unique().tolist()
        except:
            pass
    
    if len(shelf_ids) < 100:
        print("   -> èˆŠ ID å¤ªå°‘ï¼Œå¾è¨‚å–®ç”Ÿæˆè™›æ“¬ ID...")
        # å‡è¨­è¨‚å–®æœ‰ PARTCUSTIDï¼Œæˆ‘å€‘æŠŠå®ƒç•¶ä½œä¸€ç¨® IDï¼Œæˆ–è€…ç›´æ¥ç”Ÿæˆæµæ°´è™Ÿ
        shelf_ids = [f"Shelf_{i}" for i in range(len(df_orders))]
    
    print(f"   -> æº–å‚™é‡æ–°åˆ†é… {len(shelf_ids)} å€‹æ–™æ¶ ID ä½ç½®...")

    # 3. åˆ†é…åº§æ¨™ (Round-Robin)
    new_rows = []
    
    # æ··åˆ 2F å’Œ 3F çš„ç©ºä½
    all_spots = []
    for pos in shelf_spots['2F']: all_spots.append(('2F', pos))
    for pos in shelf_spots['3F']: all_spots.append(('3F', pos))
    
    if not all_spots:
        print("âŒ ç„¡è™•å¯æ”¾ï¼")
        return
        
    random.shuffle(all_spots) # æ´—ç‰Œï¼Œè®“åˆ†ä½ˆæ›´å‡å‹»
    
    for i, sid in enumerate(shelf_ids):
        # è¼ªè©¢åˆ†é…
        floor, (x, y) = all_spots[i % len(all_spots)]
        new_rows.append({
            'shelf_id': sid,
            'floor': floor,
            'x': x,
            'y': y
        })
        
    # 4. å­˜æª”
    df_new = pd.DataFrame(new_rows)
    df_new.to_csv(OUTPUT_MAP_FILE, index=False, encoding='utf-8')
    print(f"âœ… ä¿®å¾©å®Œæˆï¼å·²å„²å­˜è‡³ {OUTPUT_MAP_FILE}")
    print("   -> è«‹é‡æ–°åŸ·è¡Œ Step 4 (æ¨¡æ“¬) èˆ‡ Step 5 (è¦–è¦ºåŒ–)")

if __name__ == "__main__":
    repair_mapping()